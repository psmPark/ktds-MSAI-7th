import azure.functions as func
import logging
import json
import os
import re

# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ (pip install openai)
from openai import AzureOpenAI

# Azure Search ë¼ì´ë¸ŒëŸ¬ë¦¬ (pip install azure-search-documents)
from azure.search.documents import SearchClient
from azure.search.documents.models import QueryType

# ======================================================================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Function App ì„¤ì •ì— ë°˜ë“œì‹œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.)
# ======================================================================
OPENAI_ENDPOINT = os.environ.get("OPENAI_ENDPOINT")
OPENAI_KEY = os.environ.get("OPENAI_KEY")
OPENAI_DEPLOYMENT = os.environ.get("OPENAI_DEPLOYMENT_NAME", "gpt-35-turbo")

SEARCH_ENDPOINT = os.environ.get("AZURE_AI_SEARCH_ENDPOINT")
SEARCH_KEY = os.environ.get("AZURE_AI_SEARCH_API_KEY")
SEARCH_INDEX_NAME_RULES = os.environ.get(
    "AZURE_AI_SEARCH_INDEX_NAME_RULES", "coding-convention-index"
)  # ëª…ëª… ê·œì¹™ ì¸ë±ìŠ¤
SEARCH_INDEX_NAME_QA = os.environ.get(
    "AZURE_AI_SEARCH_INDEX_NAME_QA", "qna-convention-index"
)  # Q&A ì¸ë±ìŠ¤


# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# NOTE: Azure Function App í™˜ê²½ ë³€ìˆ˜ì— OPENAI_ENDPOINT, OPENAI_KEY ë“±ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
openai_client = AzureOpenAI(
    api_key=OPENAI_KEY, azure_endpoint=OPENAI_ENDPOINT, api_version="2024-02-15-preview"
)


# ----------------------------------------------------------------------
# ğŸ“š ìš©ì–´ì‚¬ì „ ë°ì´í„° ë¡œë“œ (Source 2)
# ----------------------------------------------------------------------
DICTIONARY_FILE_PATH = os.path.join(os.path.dirname(__file__), "dictionary.json")

# ìš©ì–´ì‚¬ì „ JSON ë°°ì—´ êµ¬ì¡° ì˜ˆì‹œ (ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ì‚¬ìš©)
SAMPLE_DICTIONARY_ARRAY = [
    {
        "korean": "ìƒí’ˆ",
        "english": "Product",
        "abbreviation": "PROD",
        "description": "ì†Œë¹„ìì—ê²Œ íŒë§¤í•˜ëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ë¬¼í’ˆ.",
    },
    {
        "korean": "ì¬ê³ ",
        "english": "Stock/Inventory",
        "abbreviation": "INV",
        "description": "í˜„ì¬ íŒë§¤ ë˜ëŠ” ë°°ì†¡ ê°€ëŠ¥í•œ ìƒíƒœë¡œ ì°½ê³ ì— ë³´ê´€ ì¤‘ì¸ ìƒí’ˆ ìˆ˜ëŸ‰.",
    },
    {
        "korean": "í’ˆì ˆ",
        "english": "Sold Out",
        "abbreviation": "OOS",
        "description": "ì¬ê³ ê°€ ëª¨ë‘ ì†Œì§„ë˜ì–´ ì¼ì‹œì  ë˜ëŠ” ì˜êµ¬ì ìœ¼ë¡œ êµ¬ë§¤í•  ìˆ˜ ì—†ëŠ” ìƒíƒœ. (Out Of Stock)",
    },
    {
        "korean": "í• ì¸",
        "english": "Discount",
        "abbreviation": "DC",
        "description": "ì •ê°€ì—ì„œ ì¼ì • ë¹„ìœ¨ì´ë‚˜ ê¸ˆì•¡ì„ ë¹¼ì£¼ëŠ” íŒë§¤ ë°©ì‹.",
    },
    {
        "korean": "ì •ê°€",
        "english": "Regular Price",
        "abbreviation": "RP",
        "description": "í• ì¸ì´ë‚˜ í”„ë¡œëª¨ì…˜ì´ ì ìš©ë˜ì§€ ì•Šì€ ë³¸ë˜ì˜ íŒë§¤ ê°€ê²©.",
    },
]


def load_dictionary():
    """ìš©ì–´ì‚¬ì „ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í•œêµ­ì–´ ìš©ì–´ë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        if os.path.exists(DICTIONARY_FILE_PATH):
            with open(DICTIONARY_FILE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
        else:
            logging.warning(
                f"ìš©ì–´ì‚¬ì „ íŒŒì¼ {DICTIONARY_FILE_PATH}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
            )
            data = SAMPLE_DICTIONARY_ARRAY

        # [ { "korean": "ìƒí’ˆ", ... } ] -> { "ìƒí’ˆ": { "english": "Product", ... } } í˜•íƒœë¡œ ë³€í™˜
        converted_dict = {item["korean"]: item for item in data}
        return converted_dict

    except Exception as e:
        logging.error(f"ìš©ì–´ì‚¬ì „ ë¡œë“œ ë˜ëŠ” ë³€í™˜ ì˜¤ë¥˜: {e}")
        return {}


DICTIONARY_DATA = load_dictionary()


# ----------------------------------------------------------------------
# 1. í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ (LLM í™œìš© - Retrieval Query ìƒì„±)
# ----------------------------------------------------------------------
def extract_keywords_with_llm(user_request: str) -> tuple[list, str]:
    """GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì™€ ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì—ì„œ ëª…ëª… ê·œì¹™ ë° ìš©ì–´ ê²€ìƒ‰ì— í•„ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œ(Key Term)ì™€ ì¹´í…Œê³ ë¦¬(Java, Database, WebUI)ë¥¼
        ìµœëŒ€ 5ê°œê¹Œì§€ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶”ì¶œí•˜ì„¸ìš”.

        ìš”ì²­: {user_request} ->
        """

        response = openai_client.chat.completions.create(
            model=OPENAI_DEPLOYMENT,
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant for keyword extraction.",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.0,
        )

        keywords_str = response.choices[0].message.content.strip()
        keywords_list = [k.strip() for k in keywords_str.split(",") if k.strip()]
        search_query = " OR ".join(keywords_list)

        return keywords_list, search_query

    except Exception as e:
        logging.error(f"OpenAI í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return [user_request], user_request


# ----------------------------------------------------------------------
# 2. ìš©ì–´ì‚¬ì „ ê²€ìƒ‰ í•¨ìˆ˜ (Retrieval Source 2)
# ----------------------------------------------------------------------
def search_dictionary_for_terms(keywords: list) -> list:
    """ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš©ì–´ì‚¬ì „ íŒŒì¼ì—ì„œ ì •ì˜ëœ ìš©ì–´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    dictionary_context = []

    for term_kr, term_data in DICTIONARY_DATA.items():
        is_match = any(
            keyword.lower() in term_kr.lower() or term_kr.lower() in keyword.lower()
            for keyword in keywords
        )

        if is_match:
            context = f"[Context: ìš©ì–´ì‚¬ì „] **í•œêµ­ì–´**: {term_kr} **ì˜ë¬¸**: {term_data.get('english', 'N/A')} **ì•½ì–´**: {term_data.get('abbreviation', 'N/A')} **ì„¤ëª…**: {term_data.get('description', 'N/A')}"
            if context not in dictionary_context:
                dictionary_context.append(context)

    return dictionary_context


# ----------------------------------------------------------------------
# 3. Azure AI Search í˜¸ì¶œ ë° Context ê²€ìƒ‰ í•¨ìˆ˜ (Retrieval Source 1: ëª…ëª… ê·œì¹™)
# ----------------------------------------------------------------------
def search_rules_for_context(search_query: str) -> list:
    """ëª…ëª… ê·œì¹™ ì¸ë±ìŠ¤ì—ì„œ Contextë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        search_client = SearchClient(
            SEARCH_ENDPOINT, SEARCH_INDEX_NAME_RULES, SEARCH_KEY
        )

        results = search_client.search(
            search_query,
            select=["category", "type", "rule_en", "rule_kr", "example"],
            top=3,
            query_type=QueryType.FULL,
        )

        context_list = []
        for result in results:
            context = f"[Context: {result['category']} {result['type']} Rule] **ê·œì¹™**: {result['rule_kr']} **ì˜ˆì‹œ**: {', '.join(result['example'])}"
            context_list.append(context)

        return context_list

    except Exception as e:
        logging.error(f"Azure AI Search (Rules) ì˜¤ë¥˜: {e}")
        return []


# ----------------------------------------------------------------------
# 4. Azure AI Search í˜¸ì¶œ ë° Context ê²€ìƒ‰ í•¨ìˆ˜ (Retrieval Source 3: Q&A)
# ----------------------------------------------------------------------
def search_qa_for_context(search_query: str) -> list:
    """Q&A ì¸ë±ìŠ¤ì—ì„œ Contextë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        search_client = SearchClient(SEARCH_ENDPOINT, SEARCH_INDEX_NAME_QA, SEARCH_KEY)

        results = search_client.search(
            search_query,
            select=["category", "question", "answer"],
            top=2,
            query_type=QueryType.FULL,
        )

        context_list = []
        for result in results:
            context = f"[Context: QA-{result['category']}] **ì§ˆë¬¸**: {result['question']} **ë‹µë³€**: {result['answer']}"
            context_list.append(context)

        return context_list

    except Exception as e:
        logging.error(f"Azure AI Search (QA) ì˜¤ë¥˜: {e}")
        return []


# ----------------------------------------------------------------------
# 5. ìµœì¢… ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (Generation)
# ----------------------------------------------------------------------
def generate_response_with_llm(user_request: str, context_list: list) -> str:
    """ê²€ìƒ‰ëœ Contextë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    context_str = "\n".join(context_list)

    # System PromptëŠ” LLMì—ê²Œ ëª…í™•í•œ ì—­í• ê³¼ Context í™œìš© ì§€ì¹¨ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.
    system_prompt = f"""
    ë‹¹ì‹ ì€ ì½”ë”© ëª…ëª… ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìƒˆë¡œìš´ ë³€ìˆ˜ëª…ì´ë‚˜ í•¨ìˆ˜ëª…ì„ ìƒì„±í•˜ê³ ,
    ëª…ëª… ê·œì¹™ ë˜ëŠ” ìš©ì–´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
    
    **ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì‚¬í•­:**
    1. ì•„ë˜ 'ê²€ìƒ‰ëœ ê·œì¹™', 'ìš©ì–´ì‚¬ì „', 'Q&A'ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    2. ìƒˆë¡œìš´ ëª…ëª…ì„ ìƒì„±í•  ê²½ìš°, í•´ë‹¹ë˜ëŠ” ê·œì¹™(ì˜ˆ: camelCase, PascalCase, ë™ì‚¬ ì‹œì‘ ë“±)ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
    3. ìš©ì–´ì‚¬ì „ì—ì„œ ì°¾ì€ ì˜ë¬¸ ëŒ€ì•ˆì´ë‚˜ ì•½ì–´ë¥¼ í™œìš©í•˜ì—¬ ìƒì„±ëœ ìš©ì–´ì˜ ëª…í™•ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    4. Q&A ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì°¾ì•˜ë‹¤ë©´, í•´ë‹¹ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€ì˜ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.

    **ê²€ìƒ‰ëœ ê·œì¹™ ë° ìš©ì–´ (Context):**
    ---
    {context_str}
    ---
    """

    try:
        response = openai_client.chat.completions.create(
            model=OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_request},
            ],
            temperature=0.3,
        )

        return response.choices[0].message.content

    except Exception as e:
        logging.error(f"OpenAI ìµœì¢… ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {e})"


# ----------------------------------------------------------------------
# ğŸŒ ë©”ì¸ Function App ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ (í†µí•©ëœ RAG ë¡œì§)
# ----------------------------------------------------------------------
def main(req: func.HttpRequest) -> func.HttpResponse:
    logging.info("Python HTTP trigger function processed a request.")

    # 1. ìš”ì²­ ìˆ˜ì‹  ë° ê²€ì¦
    try:
        req_body = req.get_json()
        user_request = req_body.get("request_text")
        if not user_request:
            raise ValueError("ìš”ì²­ ë³¸ë¬¸ì— 'request_text' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    except Exception as e:
        return func.HttpResponse(str(e), status_code=400)

    # 2. í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords_list, search_query = extract_keywords_with_llm(user_request)

    # 3. ëª…ëª… ê·œì¹™ Context ê²€ìƒ‰ (Source 1)
    rules_context = search_rules_for_context(search_query)

    # 4. ìš©ì–´ì‚¬ì „ì—ì„œ ê´€ë ¨ ìš©ì–´ Context ê²€ìƒ‰ (Source 2)
    dictionary_context = search_dictionary_for_terms(keywords_list)

    # 5. Q&A Context ê²€ìƒ‰ (Source 3)
    qa_context = search_qa_for_context(search_query)

    # 6. ëª¨ë“  Contextë¥¼ í†µí•©
    all_context = rules_context + dictionary_context + qa_context
    logging.info(f"í†µí•©ëœ Context ê°œìˆ˜: {len(all_context)}")

    # 7. Azure OpenAIê°€ ìµœì¢… ìƒì„± ë° ë³´ì • ìˆ˜í–‰ (Generation)
    final_answer = generate_response_with_llm(user_request, all_context)

    # 8. ê²°ê³¼ ë°˜í™˜
    response_data = {
        "final_answer": final_answer,
        "search_query_used": search_query,
        "retrieved_context_count": len(all_context),
    }

    return func.HttpResponse(
        json.dumps(response_data, ensure_ascii=False),
        mimetype="application/json",
        status_code=200,
    )
